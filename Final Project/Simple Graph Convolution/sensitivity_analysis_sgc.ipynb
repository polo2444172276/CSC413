{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "W18tDzlM0yDP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle as pkl\n",
    "from time import perf_counter\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import sys\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qFD-yY29AGP-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def f1(output, labels):\n",
    "    preds = output.max(1)[1]\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    micro = f1_score(labels, preds, average='micro')\n",
    "    macro = f1_score(labels, preds, average='macro')\n",
    "    return micro, macro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jyKD8GBnefg5"
   },
   "outputs": [],
   "source": [
    "class SGC(nn.Module):\n",
    "    \"\"\"\n",
    "    A Simple PyTorch Implementation of Logistic Regression.\n",
    "    Assuming the features have been preprocessed with k-step graph propagation.\n",
    "    \"\"\"\n",
    "    def __init__(self, nfeat, nclass):\n",
    "        super(SGC, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(nfeat, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.W(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GWygoqbl-pyp"
   },
   "outputs": [],
   "source": [
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "def row_normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def normalization(adj):\n",
    "   adj = adj + sp.eye(adj.shape[0])\n",
    "   adj = sp.coo_matrix(adj)\n",
    "   row_sum = np.array(adj.sum(1))\n",
    "   d_inv_sqrt = np.power(row_sum, -0.5).flatten()\n",
    "   d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "   d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "   return d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def preprocess_citation(adj, features):\n",
    "    adj = normalization(adj)\n",
    "    features = row_normalize(features)\n",
    "    return adj, features\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def load_citation(dataset_str=\"cora\", cuda=True):\n",
    "    \"\"\"\n",
    "    Load Citation Networks Datasets.\n",
    "    \"\"\"\n",
    "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"data/ind.{}.{}\".format(dataset_str.lower(), names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    labels = np.vstack((ally, ty))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "    idx_test = test_idx_range.tolist()\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "    adj, features = preprocess_citation(adj, features)\n",
    "\n",
    "    # porting to pytorch\n",
    "    features = torch.FloatTensor(np.array(features.todense())).float()\n",
    "    labels = torch.LongTensor(labels)\n",
    "    labels = torch.max(labels, dim=1)[1]\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj).float()\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test\n",
    "\n",
    "def sgc_precompute(features, adj, degree):\n",
    "    t = perf_counter()\n",
    "    for i in range(degree):\n",
    "        features = torch.spmm(adj, features)\n",
    "    precompute_time = perf_counter()-t\n",
    "    return features, precompute_time\n",
    "\n",
    "def set_seed(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda: torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "KNyGkZ2q31A5"
   },
   "outputs": [],
   "source": [
    "def train_regression(model,\n",
    "                     train_features, train_labels,\n",
    "                     val_features, val_labels,\n",
    "                     epochs, weight_decay, lr):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    t = perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_features)\n",
    "        loss_train = F.cross_entropy(output, train_labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    train_time = perf_counter()-t\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(val_features)\n",
    "        acc_val = accuracy(output, val_labels)\n",
    "\n",
    "    return model, acc_val, train_time\n",
    "\n",
    "def test_regression(model, test_features, test_labels):\n",
    "    model.eval()\n",
    "    return accuracy(model(test_features), test_labels)\n",
    "def run(dataset=\"cora\", cuda=False, degree=2, weight_decay=0.005, lr=0.2, epochs=100):\n",
    "  # setting random seeds\n",
    "  set_seed(42, False)\n",
    "\n",
    "  adj, features, labels, idx_train, idx_val, idx_test = load_citation(dataset, cuda)\n",
    "  model = SGC(nfeat=features.size(1),\n",
    "                    nclass=labels.max().item()+1)\n",
    "\n",
    "  features, precompute_time = sgc_precompute(features, adj, degree)\n",
    "\n",
    "\n",
    "  model, acc_val, train_time = train_regression(model, features[idx_train], labels[idx_train], features[idx_val], labels[idx_val],\n",
    "                    epochs, weight_decay, lr)\n",
    "  acc_test = test_regression(model, features[idx_test], labels[idx_test])\n",
    "  print(\"Hyperparams: degree:{}, weight_decay:{}, lr:{}, epochs:{}\".format(degree, weight_decay, lr, epochs))\n",
    "  print(\"Validation Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(acc_val, acc_test))\n",
    "  print(\"Pre-compute time: {:.4f}s, train time: {:.4f}s, total: {:.4f}s\\n\".format(precompute_time, train_time, precompute_time+train_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSECYQvS5sWq"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uaqUyVWx1aa1",
    "outputId": "3cd372ea-ad39-40cc-92a3-b18725cf5e23",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams: degree:1, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7060 Test Accuracy: 0.7380\n",
      "Pre-compute time: 0.0105s, train time: 0.0833s, total: 0.0938s\n",
      "Hyperparams: degree:2, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7620 Test Accuracy: 0.7740\n",
      "Pre-compute time: 0.0227s, train time: 0.0894s, total: 0.1121s\n",
      "Hyperparams: degree:3, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7660 Test Accuracy: 0.7670\n",
      "Pre-compute time: 0.0360s, train time: 0.0777s, total: 0.1137s\n",
      "Hyperparams: degree:4, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7620 Test Accuracy: 0.7700\n",
      "Pre-compute time: 0.0508s, train time: 0.0814s, total: 0.1322s\n",
      "Hyperparams: degree:5, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7620 Test Accuracy: 0.7710\n",
      "Pre-compute time: 0.0591s, train time: 0.0760s, total: 0.1351s\n",
      "Hyperparams: degree:6, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7580 Test Accuracy: 0.7730\n",
      "Pre-compute time: 0.0680s, train time: 0.0775s, total: 0.1455s\n",
      "Hyperparams: degree:7, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7520 Test Accuracy: 0.7710\n",
      "Pre-compute time: 0.0818s, train time: 0.0803s, total: 0.1620s\n",
      "Hyperparams: degree:8, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7560 Test Accuracy: 0.7690\n",
      "Pre-compute time: 0.0914s, train time: 0.0902s, total: 0.1816s\n",
      "Hyperparams: degree:9, weight_decay:0.005, lr:0.2, epochs:100\n",
      "Validation Accuracy: 0.7520 Test Accuracy: 0.7620\n",
      "Pre-compute time: 0.1001s, train time: 0.0796s, total: 0.1797s\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "  run(degree=i)\n",
    "# for i in np.arange(0.005, 0.1, 0.005):\n",
    "#   run(weight_decay=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning_plot(x, parm):\n",
    "  # exec(\"%s = %d\" % (parm, 1))\n",
    "  res1, res2, res3 = [], [], []\n",
    "  for i in x:\n",
    "    if parm == \"degree\":\n",
    "      acc_train, acc_val, acc_test = run(degree=i)\n",
    "    if parm == \"weight_decay\":\n",
    "      acc_train, acc_val, acc_test = run(weight_decay=i)\n",
    "    if parm == \"epochs\":\n",
    "      acc_train, acc_val, acc_test = run(epochs=i)\n",
    "    if parm == \"lr\":\n",
    "      acc_train, acc_val, acc_test = run(lr=i)\n",
    "    if parm == \"dropout\":\n",
    "      acc_train, acc_val, acc_test = run(dropout=i)\n",
    "    if parm == \"hidden\":\n",
    "      acc_train, acc_val, acc_test = run(hidden=i)    \n",
    "\n",
    "    res1.append(acc_val)\n",
    "    res2.append(acc_test)\n",
    "    res3.append(acc_train)\n",
    "  \n",
    "  plt.plot(x, res1, label=\"val\")\n",
    "  plt.plot(x, res2, label=\"test\")\n",
    "  plt.plot(x, res3, label=\"train\")\n",
    "  plt.xlabel(parm)\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  # plt.title(parm)\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2oDp0m73Gk8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sensitivity_analysis_SGC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
