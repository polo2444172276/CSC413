{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cXxetRpPmNBF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "import re\n",
    "from time import perf_counter\n",
    "import tabulate\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LBl2g_JXq4AZ"
   },
   "outputs": [],
   "source": [
    "class SGC(nn.Module):\n",
    "    def __init__(self, nfeat, nclass, bias=False):\n",
    "        super(SGC, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(nfeat, nclass, bias=bias)\n",
    "        torch.nn.init.xavier_normal_(self.W.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.W(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zSsxb_UXi1HP"
   },
   "outputs": [],
   "source": [
    "def parse_index_file(filename):\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "def load_corpus():\n",
    "    dataset_str = \"ag_news\"\n",
    "    index_dict = {}\n",
    "    label_dict = {}\n",
    "    phases = [\"train\", \"val\", \"test\"]\n",
    "    objects = []\n",
    "    def load_pkl(path):\n",
    "        with open(path.format(dataset_str, p), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                return pkl.load(f, encoding='latin1')\n",
    "            else:\n",
    "                return pkl.load(f)\n",
    "\n",
    "    for p in phases:\n",
    "        index_dict[p] = load_pkl(\"data/ind.{}.{}.x\".format(dataset_str, p))\n",
    "        label_dict[p] = load_pkl(\"data/ind.{}.{}.y\".format(dataset_str, p))\n",
    "\n",
    "    adj = load_pkl(\"data/ind.{}.BCD.adj\".format(dataset_str))\n",
    "    adj = adj.astype(np.float32)\n",
    "    adj = preprocess_adj(adj)\n",
    "\n",
    "    return adj, index_dict, label_dict\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).transpose().tocoo()\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    return adj_normalized\n",
    "\n",
    "def clean_str(string):\n",
    "    string = re.sub(r'[?|$|.|!]',r'',string)\n",
    "    string = re.sub(r'[^a-zA-Z0-9 ]',r'',string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def sparse_to_torch_sparse(sparse_mx, device='cuda'):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    if device == 'cuda':\n",
    "        indices = indices.cuda()\n",
    "        values = torch.from_numpy(sparse_mx.data).cuda()\n",
    "        shape = torch.Size(sparse_mx.shape)\n",
    "        adj = torch.cuda.sparse.FloatTensor(indices, values, shape)\n",
    "    elif device == 'cpu':\n",
    "        values = torch.from_numpy(sparse_mx.data)\n",
    "        shape = torch.Size(sparse_mx.shape)\n",
    "        adj = torch.sparse.FloatTensor(indices, values, shape)\n",
    "    return adj\n",
    "\n",
    "def sparse_to_torch_dense(sparse, device='cuda'):\n",
    "    dense = sparse.todense().astype(np.float32)\n",
    "    torch_dense = torch.from_numpy(dense).to(device=device)\n",
    "    return torch_dense\n",
    "\n",
    "def sgc_precompute(adj, features, degree, index_dict):\n",
    "    assert degree==1, \"Only supporting degree 2 now\"\n",
    "    feat_dict = {}\n",
    "    start = perf_counter()\n",
    "    train_feats = features[:, index_dict[\"train\"]].cuda()\n",
    "    train_feats = torch.spmm(adj, train_feats).t()\n",
    "    train_feats_max, _ = train_feats.max(dim=0, keepdim=True)\n",
    "    train_feats_min, _ = train_feats.min(dim=0, keepdim=True)\n",
    "    train_feats_range = train_feats_max-train_feats_min\n",
    "    useful_features_dim = train_feats_range.squeeze().gt(0).nonzero().squeeze()\n",
    "    train_feats = train_feats[:, useful_features_dim]\n",
    "    train_feats_range = train_feats_range[:, useful_features_dim]\n",
    "    train_feats_min = train_feats_min[:, useful_features_dim]\n",
    "    train_feats = (train_feats-train_feats_min)/train_feats_range\n",
    "    feat_dict[\"train\"] = train_feats\n",
    "    for phase in [\"test\", \"val\"]:\n",
    "        feats = features[:, index_dict[phase]].cuda()\n",
    "        feats = torch.spmm(adj, feats).t()\n",
    "        feats = feats[:, useful_features_dim]\n",
    "        feat_dict[phase] = ((feats-train_feats_min)/train_feats_range).cpu() # adj is symmetric!\n",
    "    precompute_time = perf_counter()-start\n",
    "    return feat_dict, precompute_time\n",
    "\n",
    "def set_seed(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda: torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "To5dbwXxbAmV"
   },
   "outputs": [],
   "source": [
    "def train_linear(model, feat_dict, weight_decay, binary=False):\n",
    "    if not binary:\n",
    "        act = partial(F.log_softmax, dim=1)\n",
    "        criterion = F.nll_loss\n",
    "    else:\n",
    "        act = torch.sigmoid\n",
    "        criterion = F.binary_cross_entropy\n",
    "    optimizer = optim.LBFGS(model.parameters())\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0\n",
    "    plateau = 0\n",
    "    start = time.perf_counter()\n",
    "    for epoch in range(3):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(feat_dict[\"train\"].cuda()).squeeze()\n",
    "            l2_reg = 0.5*weight_decay*(model.W.weight**2).sum()\n",
    "            loss = criterion(act(output), label_dict[\"train\"].cuda())+l2_reg\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    train_time = time.perf_counter()-start\n",
    "    val_res = eval_linear(model, feat_dict[\"val\"].cuda(),\n",
    "                          label_dict[\"val\"].cuda(), binary)\n",
    "    return val_res['accuracy'], model, train_time\n",
    "\n",
    "def eval_linear(model, features, label, binary=False):\n",
    "    model.eval()\n",
    "    if not binary:\n",
    "        act = partial(F.log_softmax, dim=1)\n",
    "        criterion = F.nll_loss\n",
    "    else:\n",
    "        act = torch.sigmoid\n",
    "        criterion = F.binary_cross_entropy\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(features).squeeze()\n",
    "        loss = criterion(act(output), label)\n",
    "        if not binary: predict_class = output.max(1)[1]\n",
    "        else: predict_class = act(output).gt(0.5).float()\n",
    "        correct = torch.eq(predict_class, label).long().sum().item()\n",
    "        acc = correct/predict_class.size(0)\n",
    "\n",
    "    return {\n",
    "        'loss': loss.item(),\n",
    "        'accuracy': acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8ALePdwetWT",
    "outputId": "6cf038b6-233d-4e72-9f44-dccf014d14f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 3.426125s, Train acc: 0.9497, Val acc: 0.8873, Test acc: 0.8737\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "set_seed(15, True)\n",
    "\n",
    "sp_adj, index_dict, label_dict = load_corpus()\n",
    "for k, v in label_dict.items():\n",
    "    label_dict[k] = torch.LongTensor(v).to(\"cuda\")\n",
    "features = torch.arange(sp_adj.shape[0]).to(\"cuda\")\n",
    "\n",
    "adj = sparse_to_torch_sparse(sp_adj, device=\"cuda\")\n",
    "adj_dense = sparse_to_torch_dense(sp_adj, device=\"cuda\")\n",
    "feat_dict, precompute_time = sgc_precompute(adj, adj_dense, 1, index_dict)\n",
    "nclass = label_dict[\"train\"].max().item()+1\n",
    "model = SGC(nfeat=feat_dict[\"train\"].size(1),\n",
    "        nclass=nclass).cuda()\n",
    "val_acc, best_model, train_time = train_linear(model, feat_dict, 0.0005)\n",
    "test_res = eval_linear(best_model, feat_dict[\"test\"].cuda(),\n",
    "                    label_dict[\"test\"].cuda())\n",
    "train_res = eval_linear(best_model, feat_dict[\"train\"].cuda(),\n",
    "                    label_dict[\"train\"].cuda())\n",
    "print(\"Total Time: {:2f}s, Train acc: {:.4f}, Val acc: {:.4f}, Test acc: {:.4f}\".format(precompute_time+train_time, train_res[\"accuracy\"], val_acc, test_res[\"accuracy\"]))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ag_news_sgc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
